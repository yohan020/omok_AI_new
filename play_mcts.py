# íŒŒì¼ëª…: play_mcts.py

import torch
import numpy as np
import time
import random

# (!!!) ì¤‘ìš”: í›ˆë ¨ ì¤‘ì¸ ResNet ëª¨ë¸ ì‚¬ìš©
from model import ResNetActorCritic
from environment import OmokEnv
from mcts import run_mcts

# (!!!) ë°©ê¸ˆ í™•ì¸í•œ ìµœì‹  ëª¨ë¸ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”
MODEL_PATH = 'models_pure_resnet/resnet_omok_model_cycle_185.pth'
BOARD_SIZE = 10
MCTS_SIMULATIONS_PLAY = 2000 # ìƒê°í•  ì‹œê°„

def print_board(board):
    print("   " + " ".join([f"{i:2}" for i in range(BOARD_SIZE)]))
    print("  " + "-" * (BOARD_SIZE * 3 - 1))
    for r in range(BOARD_SIZE):
        row_str = f"{r:2}|"
        for c in range(BOARD_SIZE):
            if board[r, c] == 1: row_str += " B "
            elif board[r, c] == -1: row_str += " W "
            else: row_str += " . "
        print(row_str)

def get_human_move(env, player_color):
    while True:
        try:
            move_str = input(f"ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤ ({player_color}). (row, col) ì…ë ¥ (0~{BOARD_SIZE-1}): ")
            row, col = map(int, move_str.split(','))
            action = row * BOARD_SIZE + col
            
            if not (0 <= row < BOARD_SIZE and 0 <= col < BOARD_SIZE):
                print("ë³´ë“œ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
            elif not env.get_valid_moves()[action]:
                print("ì´ë¯¸ ëŒì´ ìˆëŠ” ê³³ì…ë‹ˆë‹¤.")
            else:
                return action
        except ValueError:
            print("ì˜ëª»ëœ í˜•ì‹ì…ë‹ˆë‹¤. ì˜ˆ: 5, 5")

# --- [ê·œì¹™] í—¬í¼ í•¨ìˆ˜ë“¤ ---
def check_winning_move(env, player):
    """ 1. í‚¬ê° í™•ì¸ """
    for r in range(BOARD_SIZE):
        for c in range(BOARD_SIZE):
            if env.board[r, c] == 0:
                env.board[r, c] = player
                if env.check_win(r, c, player):
                    env.board[r, c] = 0
                    return r * BOARD_SIZE + c
                env.board[r, c] = 0
    return None

def get_moves_that_make_pattern(env, player, target_count, open_ends_required=2):
    """ 2. íŠ¹ì • íŒ¨í„´(ì—´ë¦° 3, ì—´ë¦° 4)ì„ ë§Œë“œëŠ” ìë¦¬ ì°¾ê¸° """
    directions = [(0, 1), (1, 0), (1, 1), (1, -1)]
    candidates = []
    for r in range(BOARD_SIZE):
        for c in range(BOARD_SIZE):
            if env.board[r, c] == 0:
                env.board[r, c] = player
                for dr, dc in directions:
                    count = 1
                    blocked = 0
                    # ì •ë°©í–¥
                    nr, nc = r + dr, c + dc
                    while 0 <= nr < BOARD_SIZE and 0 <= nc < BOARD_SIZE and env.board[nr, nc] == player:
                        count += 1; nr += dr; nc += dc
                    if not (0 <= nr < BOARD_SIZE and 0 <= nc < BOARD_SIZE and env.board[nr, nc] == 0): blocked += 1
                    # ì—­ë°©í–¥
                    nr, nc = r - dr, c - dc
                    while 0 <= nr < BOARD_SIZE and 0 <= nc < BOARD_SIZE and env.board[nr, nc] == player:
                        count += 1; nr -= dr; nc -= dc
                    if not (0 <= nr < BOARD_SIZE and 0 <= nc < BOARD_SIZE and env.board[nr, nc] == 0): blocked += 1
                    
                    if count >= target_count and (2 - blocked) >= open_ends_required:
                        candidates.append(r * BOARD_SIZE + c)
                        break
                env.board[r, c] = 0
    return candidates

def main():
    if torch.cuda.is_available(): device = torch.device("cuda")
    elif torch.backends.mps.is_available(): device = torch.device("mps")
    else: device = torch.device("cpu")
    print(f"Using device: {device}")

    # (!!!) í›ˆë ¨ ì¤‘ì¸ ResNet ëª¨ë¸ ë¡œë“œ
    model = ResNetActorCritic(board_size=BOARD_SIZE).to(device)
    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        print(f"ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {MODEL_PATH}")
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ -> {MODEL_PATH}")
        return
        
    model.eval()
    env = OmokEnv(board_size=BOARD_SIZE)
    state = env.reset()
    done = False
    
    human_player = 0
    human_color_str = ""
    ai_color_str = ""
    while human_player == 0:
        choice = input("í‘ëŒ(B, ì„ ê³µ) ë˜ëŠ” ë°±ëŒ(W, í›„ê³µ)ì„ ì„ íƒí•˜ì„¸ìš”: ").upper()
        if choice == 'B': human_player = 1; human_color_str = "í‘ëŒ"; ai_color_str = "ë°±ëŒ"
        elif choice == 'W': human_player = -1; human_color_str = "ë°±ëŒ"; ai_color_str = "í‘ëŒ"
    
    print(f"\në‹¹ì‹ ì€ {human_color_str}, AIëŠ” {ai_color_str}ì…ë‹ˆë‹¤.")
    
    if human_player == -1:
        print_board(env.board)
        print(f"\nğŸ¤– AI({ai_color_str})ê°€ ì²« ìˆ˜ë¥¼ ë‘¡ë‹ˆë‹¤...")
        # ì²« ìˆ˜ëŠ” ìˆœìˆ˜ ëª¨ë¸ì˜ íŒë‹¨(MCTS)ì— ë§¡ê¹€
        action, _ = run_mcts(env, model, device, num_simulations=MCTS_SIMULATIONS_PLAY, c_puct=1.0)
        row, col = divmod(action, BOARD_SIZE)
        print(f"ğŸ¤– AI ì°©ìˆ˜: ({row}, {col})")
        state, _, _ = env.step(action)

    while not done:
        print_board(env.board)
        
        if env.current_player == human_player:
            action = get_human_move(env, human_color_str)
        else:
            print(f"\nğŸ¤– AI({ai_color_str})ê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤...")
            ai_player = env.current_player
            opponent = -ai_player
            action = -1
            
            # --- [ê·œì¹™ 1] í‚¬ê° (5ëª©) ---
            win_move = check_winning_move(env, ai_player)
            if win_move is not None:
                print("âš¡ AI: ì²´í¬ë©”ì´íŠ¸! (ìŠ¹ë¦¬)")
                action = win_move
            
            # --- [ê·œì¹™ 2] ì ˆëŒ€ ë°©ì–´ (ìƒëŒ€ 5ëª© ì €ì§€) ---
            if action == -1:
                block_win = check_winning_move(env, opponent)
                if block_win is not None:
                    print("ğŸ›¡ï¸ AI: 5ëª© ë°©ì–´!")
                    action = block_win

            # --- [ê·œì¹™ 3] í•„ìŠ¹ ê³µê²© (ë‚´ ì—´ë¦° 4 ë§Œë“¤ê¸°) ---
            if action == -1:
                my_open_4 = get_moves_that_make_pattern(env, ai_player, 4, 2)
                if my_open_4:
                    print("âš”ï¸ AI: í•„ìŠ¹ ê³µê²© (ì—´ë¦° 4)")
                    action = random.choice(my_open_4)

            # --- [ê·œì¹™ 4] 4ëª© ë°©ì–´ ---
            if action == -1:
                # ìƒëŒ€ê°€ ë‘ë©´ 4ê°œê°€ ë˜ëŠ”ë°, í•œìª½ì´ë¼ë„ ëš«ë ¤ìˆìœ¼ë©´(Open>=1) ë§‰ì•„ì•¼ í•¨
                opp_4 = get_moves_that_make_pattern(env, opponent, 4, 1)
                if opp_4:
                    print("ğŸ›¡ï¸ AI: 4ëª© ë°©ì–´!")
                    action = opp_4[0]

            # --- [ê·œì¹™ 5] ì‚¬ì „ ë°©ì–´ (ìƒëŒ€ ì—´ë¦° 3) ---
            if action == -1:
                opp_open_3 = get_moves_that_make_pattern(env, opponent, 3, 2)
                if opp_open_3:
                    print("ğŸ›¡ï¸ AI: 3ëª© ê²¬ì œ")
                    action = opp_open_3[0]

            # --- [ê·œì¹™ 6] ë‚´ ì—´ë¦° 3 ë§Œë“¤ê¸° (ê³µê²©) ---
            if action == -1:
                my_open_3 = get_moves_that_make_pattern(env, ai_player, 3, 2)
                if my_open_3:
                    print("âš”ï¸ AI: ê³µê²© ì „ê°œ (ì—´ë¦° 3)")
                    action = random.choice(my_open_3)

            # --- [ë³¸ëŠ¥] í›ˆë ¨ëœ ëª¨ë¸ì˜ MCTS ìˆ˜ì½ê¸° ---
            if action == -1:
                print(f"(MCTS ìˆ˜ì½ê¸° {MCTS_SIMULATIONS_PLAY}íšŒ ì§„í–‰ ì¤‘...)")
                start_time = time.time()
                # (!!!) ì—¬ê¸°ì„œ í›ˆë ¨ëœ ResNetì´ "ê°€ì¥ ìœ ë¦¬í•œ ìë¦¬"ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
                action, pi_target = run_mcts(env, model, device,
                                             num_simulations=MCTS_SIMULATIONS_PLAY,
                                             c_puct=1.0)
                end_time = time.time()
                conf = pi_target[action] * 100 if pi_target is not None and action != -1 else 0
                print(f"   -> MCTS ì™„ë£Œ ({end_time - start_time:.1f}ì´ˆ). í™•ì‹ : {conf:.1f}%")

            if action == -1:
                print("AI ê¸°ê¶Œ")
                break

            row, col = divmod(action, BOARD_SIZE)
            print(f"ğŸ¤– AI ì°©ìˆ˜: ({row}, {col})")

        state, reward, done = env.step(action)
        
        if done:
            print_board(env.board)
            if reward == 1.0:
                winner = env.current_player * -1
                if winner == human_player: print(f"\nğŸ‰ ë‹¹ì‹ ({human_color_str}) ìŠ¹ë¦¬!")
                else: print(f"\nğŸ¤– AI({ai_color_str}) ìŠ¹ë¦¬!")
            else:
                print("\në¬´ìŠ¹ë¶€/ì˜¤ë¥˜!")

if __name__ == '__main__':
    main()
